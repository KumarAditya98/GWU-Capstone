<h1>Capstone Proposal</h1>
<h2>Graph Neural Networks - Vision-Language Image Understanding</h2>
<h3>Proposed by: Aditya Kumar, Udbhav Kush, Anjali Mudgal</h3>
<h4>Email: aditya_kumar@gwu.edu; ukush4@gwu.edu; amudgal26@gwu.edu</h4>
<h4>Advisor: Amir Jafari</h4>
<h4>The George Washington University, Washington DC</h4>
<h4>Data Science Program</h4>
<h2>1 Objective:</h2>
<pre><code>        2D image understanding is a complex problem 
        within Computer Vision. It goes further than 
        identifying the objects in an image, and instead 
        it attempts to understand the scene at par with 
        human level scene comprehension. Graphs provide 
        a natural way to represent the relational 
        arrangement between objects in an image. 
        The goal of this project is to explore and 
        implement GNN based solutions for a range of 
        vision-language tasks including (1) image captioning, 
        (2) Visual Question Answering(VQA), and (3) image retrieval.
        The research paper - https://arxiv.org/pdf/2303.03761.pdf 
        provides a comprehensive survey of contemporary 
        GNN based approaches for mentioned tasks which 
        will be used as a reference. In addition, 
        PyG package and its documentation will be explored 
        for GNN implementation.
        Finally, we write a journal paper documenting the 
        effectiveness of GNN based approaches for these tasks. 
</code></pre>
<h2>2 Dataset:</h2>
<pre><code>        Vision-language tasks have their own unique datasets. 
        The aforementioned research paper cites multiple 
        standard datasets that are used as benchmark for 
        each vision-language task. These datasets will be 
        explored and picked based on availability, viability 
        and sub-task applicability.  
</code></pre>
<h2>3 Rationale:</h2>
<pre><code>        This project is going to help machine learning and 
        deep learning researches to understand contemporary 
        GNN based approaches for vision-language image understanding.
</code></pre>
<h2>4 Approach:</h2>
<pre><code>        We plan on approaching this capstone through several steps.  

        1. Literature review of all 3 vision-language tasks.
        2. Exploring GNN and their implementation through PyG documentation.  
        3. Create a basic GNN code (basic code: Data loaders, models).
        4. Create modular and reusable codes. 
        5. Work on specific application.
        6. Create a tutorial through Streamlit and slides for the specific application. 
        7. Write a journal paper. 
</code></pre>
<h2>5 Timeline:</h2>
<pre><code>        This is a rough time line for this project:  
        - (1 Weeks) Literature review on application.
        - (1 Weeks) Exploring PyG documentation and understanding GNNs.  
        - (2 Weeks) Basic GNN code and documentation.
        - (1 Weeks) Modular reusable class and functions.  
        - (4 Weeks) Tutorial and slides for specific application.
        - (1 Weeks) Write a paper. 
        - (1 Weeks) Final Presentation  
</code></pre>
<h2>6 Expected Number Students:</h2>
<pre><code>        For this project 3 students can work on it.  
</code></pre>
<h2>7 Possible Issues:</h2>
<pre><code>        The challenge is understanding the GNN in great detail. The vision-language tasks mentioned have various approaches to them. Selecting the right approach will be challenging. A comparative analysis between traditional deep learning methodologies for the same tasks will be ideal, however, implementing just the GNN approach may prove too challenging. 
</code></pre>
<h2>Contact</h2>
<ul>
<li>Author: Amir Jafari</li>
<li>Email: <a href="Eamil">ajafari@gmail.com</a></li>
<li>GitHub: <a href="Git Hub rep">https://github.com/KumarAditya98/GWU-Capstone</a></li>
</ul>
